# ============================================
# NEXUS - Environment Variables
# ============================================
# Copy this file to .env and fill in your API keys
# NEVER commit .env to git!

# ============================================
# MiniMax M2.5 - PRIMARY AI MODEL
# ============================================
# Used for: OpenClaw computer control, ORION, NOVA, PIXEL, CIPHER, FLUX
MINIMAX_API_KEY=your_minimax_api_key_here
MINIMAX_MODEL=MiniMax-M2.5
MINIMAX_ANTHROPIC_BASE_URL=https://api.minimax.io/anthropic

# GLM API (z.ai) - FALLBACK MODEL
# Used for: ECHO (testing), fallback tasks
GLM_API_KEY=your_glm_api_key_here
GLM_API_BASE=https://api.z.ai/api/openai/v1
ZAI_OPENAI_BASE_URL=https://api.z.ai/api/openai/v1
GLM_FLASH_MODEL=glm-4.7

# Google AI (Gemini) - Optional
GOOGLE_API_KEY=your_google_api_key_here

# ============================================
# OpenClaw - AI Computer Control
# ============================================
# OpenClaw is the AI agent that controls your computer
# Install: brew install openclaw
# Config: ~/.openclaw/openclaw.json

# OpenClaw Gateway Token (auto-read from ~/.openclaw/openclaw.json if not set)
OPENCLAW_GATEWAY_TOKEN=
OPENCLAW_BROWSER_AUTO_START=true
OPENCLAW_BROWSER_TIMEOUT_MS=30000
# URL that OpenClaw flow will open/control (usually Monitor dashboard URL)
OPENCLAW_DASHBOARD_URL=http://127.0.0.1:5050/
OPENCLAW_SELF_HEAL_OPEN_DASHBOARD=false
OPENCLAW_SELF_HEAL_OPEN_COOLDOWN_SEC=300
OPENCLAW_SELF_HEAL_FALLBACK_COOLDOWN_SEC=90
OPENCLAW_FLOW_OPEN_COOLDOWN_SEC=20
OPENCLAW_ACTION_DEBOUNCE_SEC=6
OPENCLAW_AUTO_IDEMPOTENCY_ENABLED=true
OPENCLAW_AUTO_IDEMPOTENCY_WINDOW_SEC=8
OPENCLAW_AUTO_ATTACH_ENABLED=true
OPENCLAW_AUTO_ATTACH_RETRIES=2
OPENCLAW_AUTO_ATTACH_DELAY_SEC=1.2
OPENCLAW_POLICY_MOSTLY_AUTO=true
OPENCLAW_CIRCUIT_TRIGGER_COUNT=3
OPENCLAW_CIRCUIT_OPEN_SEC=60
OPENCLAW_CIRCUIT_CLASS_BLOCK_SEC=300
OPENCLAW_CIRCUIT_ESCALATE_AFTER=2
OPENCLAW_REQUIRE_TASK_LEASE=false
OPENCLAW_LEASE_HEARTBEAT_SEC=90
OPENCLAW_HIGH_RISK_ALLOWLIST=status,start,snapshot,open,navigate,hard_refresh,click,type,press,attach,flow
OPENCLAW_CRITICAL_KEYWORDS=shutdown,rm -rf,delete all,wipe,kill -9,format
MONITOR_AUTOPILOT_OPENCLAW_FLOW_ENABLED=true
MONITOR_AUTOPILOT_OPENCLAW_FLOW_COOLDOWN_SEC=120
MONITOR_AUTOPILOT_OPENCLAW_FLOW_CHAT=auto unstick run one cycle resume

# Distributed control-plane / guardian control
CONTROL_PLANE_DEFAULT_LEASE_TTL_SEC=35
CONTROL_PLANE_MAX_WORKERS=120
ORION_INSTANCE_ID=orion
ORION_CONTROL_PLANE_HEARTBEAT_SEC=10
ORION_TASK_LEASE_HEARTBEAT_SEC=60
GUARDIAN_CONTROL_TOKEN=
MONITOR_AUTOPILOT_ENABLED=true
AUTONOMY_PROFILE=full_auto
MONITOR_FULL_AUTO_USER_PAUSE_MAX_SEC=240
MONITOR_FULL_AUTO_MAINTENANCE_LEASE_SEC=180
AUTODEV_24X7_LOG_PATH=logs/run_system_24x7.log
AUTODEV_24X7_STOP_FLAG=data/state/autodev_runtime.stop
AUTODEV_24X7_HEALTH_PATH=/api/status
AUTODEV_24X7_HEALTH_TIMEOUT_SEC=6
AUTODEV_24X7_RESTART_DELAY_SEC=3
AUTODEV_24X7_EXTRA_ARGS=
AUTODEV_24X7_STOP_BEHAVIOR=resume
AUTODEV_FORCE_STALE_LOCK_CLEANUP=true
OPENCLAW_WATCHDOG_LOG_PATH=logs/openclaw_watchdog.log
OPENCLAW_WATCHDOG_STOP_FLAG=data/state/openclaw_watchdog.stop
OPENCLAW_WATCHDOG_INTERVAL_SEC=30
OPENCLAW_WATCHDOG_RESTART_ON_FAIL=true
OPENCLAW_WATCHDOG_FAIL_THRESHOLD=2
OPENCLAW_WATCHDOG_RESTART_COOLDOWN_SEC=120
OPENCLAW_WATCHDOG_STOP_BEHAVIOR=resume

# Claude Code profile (supports Anthropic-compatible and OpenAI-compatible)
# Provider options:
# - minimax / anthropic_compatible: use CLAUDE_CODE_BASE_URL directly
# - openai_compatible: auto-start local LiteLLM gateway for Claude Code
# - codaxer: same as openai_compatible but prefer CODAXER_* vars
# - auto: try Anthropic endpoint first, fallback to LiteLLM gateway
CLAUDE_CODE_PROVIDER=minimax
CLAUDE_CODE_API_KEY=your_claude_profile_key_here
CLAUDE_CODE_BASE_URL=https://api.minimax.io/anthropic
CLAUDE_CODE_MODEL=MiniMax-M2.5

# Optional model map when provider=openai_compatible
CLAUDE_CODE_MODEL_SONNET=gpt-5.1-codex
CLAUDE_CODE_MODEL_OPUS=gpt-5.1-codex-max
CLAUDE_CODE_MODEL_HAIKU=gpt-5.1-codex-mini
CLAUDE_CODE_GATEWAY_HOST=127.0.0.1
CLAUDE_CODE_GATEWAY_PORT=4000
CLAUDE_CODE_GATEWAY_TOKEN=sk-litellm-local
CLAUDE_CODE_FORCE_GATEWAY=false

# Optional fallback profile alias (works with same OpenAI-compatible gateway flow)
CODAXER_API_KEY=
CODAXER_BASE_URL=
CODAXER_MODEL_SONNET=
CODAXER_MODEL_OPUS=
CODAXER_MODEL_HAIKU=
CODAXER_MODELS=

# ============================================
# Model Configuration
# ============================================

# Routing mode:
# - adaptive: multi-model routing + fallback + budget-aware downgrade
# - single: force one model for all tasks
MODEL_ROUTING_MODE=adaptive
SINGLE_MODEL_MODE=false
DEFAULT_SINGLE_MODEL=glm-5

# Smart runtime routing retries on timeout/rate-limit/quota
ENABLE_SMART_ROUTING=true
ROUTER_CONTINUE_ON_NON_RETRYABLE_API_ERROR=true

# Daily budget controls (router tracks usage in data/state/model_usage_YYYYMMDD.json)
ROUTER_DAILY_BUDGET_USD=15
ROUTER_SOFT_BUDGET_RATIO=0.85
ROUTER_STATE_DIR=data/state
LEARNING_RUNTIME_LOCK_PATH=data/state/learning_runtime.lock
AUTODEV_RUNTIME_LOCK_PATH=data/state/autodev_runtime.lock

# Global prompt system (non-negotiable directives injected into every agent call)
ENABLE_CORE_PROMPT_SYSTEM=true
PROMPT_SYSTEM_MAX_DIRECTIVES=100
ENABLE_PROMPT_SYSTEM_TRACKLOG=true
PROMPT_SYSTEM_MAX_INJECTED_DIRECTIVES=4
PROMPT_SYSTEM_LOW_IMPORTANCE_DIRECTIVES=2
PROMPT_SYSTEM_LOW_IMPORTANCE_COMPACT=true
PROMPT_SYSTEM_INCLUDE_PROFILE_LOW_IMPORTANCE=false

# Self-learning optimization knobs
PROPOSAL_SCORE_THRESHOLD=6.2
ENABLE_AUTO_APPROVE_PROPOSALS=true
AUTO_APPROVE_PROPOSAL_SCORE=8.5
SCAN_LOG_MAX_ENTRIES=1000
PROPOSAL_HISTORY_MAX=1500
SOURCE_BACKOFF_BASE_SECONDS=600
SOURCE_BACKOFF_MAX_SECONDS=21600
MEMORY_AUTO_REPAIR_INDEX=true

# CAFE (Confidence-Aware Feedback Ensemble) + calibration
ENABLE_CAFE_LOOP=true
CAFE_CONFIDENCE_MIN=0.6
CAFE_HELPFUL_MIN=0.5
CAFE_HARMLESS_MIN=0.55
CAFE_WEIGHT_HELPFUL=0.5
CAFE_WEIGHT_HARMLESS=0.3
CAFE_WEIGHT_RELIABILITY=0.2
CAFE_ALLOW_BLOCKED_PROPOSALS=false
# Optional per-model bias (JSON map, keys can be substrings)
# CAFE_MODEL_CONF_BIAS_JSON={"codex":0.05,"gpt":0.0,"claude":-0.02}
CAFE_MODEL_CONF_BIAS_JSON=
ENABLE_CAFE_CALIBRATION=true
CAFE_CALIBRATION_INTERVAL_SECONDS=21600
CAFE_CALIBRATION_MIN_SAMPLES=6
CAFE_CALIBRATION_BIAS_SCALE=0.12
CAFE_CALIBRATION_BIAS_CAP=0.15
CAFE_CALIBRATION_SMOOTHING=0.3
CAFE_MODEL_FAMILY_KEYS=codex,gpt,chatgpt,claude,sonnet,opus,haiku,gemini

# Verification holdout (avoid premature inconclusive verdicts)
VERIFICATION_HOLDOUT_ENABLED=true
VERIFICATION_HOLDOUT_SECONDS=180
VERIFICATION_MULTI_SAMPLE_ENABLED=true
VERIFICATION_MULTI_SAMPLE_COUNT=3
VERIFICATION_MULTI_SAMPLE_INTERVAL_SECONDS=0
VERIFICATION_THRESHOLD_MIN_SAMPLES=6
VERIFICATION_THRESHOLD_SMOOTHING=0.3

# Advanced learning (spaced repetition / active recall runtime)
ENABLE_ADVANCED_LEARNING=true
ADVANCED_REVIEW_LIMIT=5
ADVANCED_INGEST_LIMIT=8
ADVANCED_LEARNING_MAX_ITEMS=800
ADVANCED_LEARNING_MAX_SESSIONS=500

# Daily R&D note logging (captures runtime issues/improvements automatically)
ENABLE_DAILY_RND_NOTES=true
RND_NOTE_MAX_MESSAGE_CHARS=800
ENABLE_ITERATION_SELF_CHECK=true
SELF_CHECK_WARN_STREAK=8
ENABLE_STAGNATION_UNBLOCK=true
UNBLOCK_MIN_PROPOSAL_SCORE=7.2
UNBLOCK_MAX_AUTO_APPROVALS_PER_ITERATION=1
ENABLE_ANOMALY_AUTOPAUSE=true
ANOMALY_OPEN_ISSUES_THRESHOLD=3
ANOMALY_HEALTH_SCORE_THRESHOLD=55
ANOMALY_ERROR_COUNT_THRESHOLD=4
ANOMALY_AUTOPAUSE_COOLDOWN_SECONDS=1800
ANOMALY_PRESSURE_SCALE=0.15
ANOMALY_RECOVERY_HEALTH_SCORE=82
ANOMALY_RECOVERY_OPEN_ISSUES_MAX=0
ANOMALY_RECOVERY_WINS_REQUIRED=2
ROLLBACK_LOCK_LOSS_STREAK_THRESHOLD=2
ROLLBACK_LOCK_COOLDOWN_SECONDS=3600
ENABLE_DAILY_SELF_LEARNING=true
DAILY_SELF_LEARNING_INTERVAL_SECONDS=86400
DAILY_SELF_LEARNING_MIN_INTERVAL_SECONDS=3600
DAILY_SELF_LEARNING_MAX_INTERVAL_SECONDS=172800
DAILY_SELF_LEARNING_STAGNATION_FACTOR=0.5
DAILY_SELF_LEARNING_INSTABILITY_FACTOR=2.0
DAILY_CADENCE_MIN_SWITCH_SECONDS=900
DAILY_SELF_LEARNING_MAX_EXPERIMENTS=3
DAILY_SELF_LEARNING_MAX_IDEAS=6
DEFAULT_FOCUS_AREA=reliability
FOCUS_ROTATION_WARN_STREAK=8
SCAN_OPERATION_LOCK_PATH=data/state/knowledge_scan.lock
IMPROVEMENT_OPERATION_LOCK_PATH=data/state/improvement_apply.lock
DAILY_CYCLE_OPERATION_LOCK_PATH=data/state/daily_self_learning.lock

# Debugger storage caps
DEBUGGER_SESSION_HISTORY_MAX=300
DEBUGGER_METRICS_HISTORY_MAX=1500
DEBUGGER_RESOLVED_ISSUES_MAX=1000
DEBUGGER_OPEN_ISSUES_MAX=500

# Optional subscription profiles (used in policy chain for critical tasks)
CODEX_SUBSCRIPTION_AVAILABLE=false
CODEX_SUBSCRIPTION_MODEL=codex-5.3-x2
CODEX_SUBSCRIPTION_LOW_MODEL=codex-5.3-mini
CLAUDE_CODE_SUBSCRIPTION_AVAILABLE=false
GEMINI_SUBSCRIPTION_AVAILABLE=false
GEMINI_SUBSCRIPTION_FLASH_MODEL=gemini-3.0-flash
GEMINI_SUBSCRIPTION_PRO_MODEL=gemini-3.0-pro

# Subscription CLI integration (Codex/Claude/Gemini) for critical fallback
ENABLE_SUBSCRIPTION_FALLBACK=false
SUBSCRIPTION_FALLBACK_CRITICAL_ONLY=false
SUBSCRIPTION_FIRST_FOR_CRITICAL=false
ENABLE_SUBSCRIPTION_PRIMARY_ROUTING=false
ENABLE_AUTO_SUBSCRIPTION_COST_ROUTING=true
SUBSCRIPTION_PRIMARY_COST_ONLY=true
SUBSCRIPTION_TIMEOUT_SEC=120
SUBSCRIPTION_FAILURE_THRESHOLD=2
SUBSCRIPTION_FAILURE_COOLDOWN_SEC=180

# CLI command + args. Supports {prompt} and {model} placeholders.
# Example: CODEX_CLI_ARGS=-m {model} -p {prompt}
CODEX_CLI_CMD=codex
CODEX_CLI_ARGS=-p
CLAUDE_CLI_CMD=claude
CLAUDE_CLI_ARGS=-p
GEMINI_CLI_CMD=gemini
GEMINI_CLI_ARGS=-m {model} -p

# Primary models
ORCHESTRATOR_MODEL=glm-5
VISION_MODEL=glm-4.6v
CODE_MODEL=glm-5
SECURITY_MODEL=glm-5
TEST_MODEL=glm-4.7
DEVOPS_MODEL=glm-5

# Orchestration cadence + cost controls
DEFAULT_COST_GUARD_MODE=economy
AUTO_COST_GUARD_ENABLED=true
AUTO_COST_GUARD_WARN_RATIO=0.72
AUTO_COST_GUARD_HARD_RATIO=0.90
AUTO_COST_GUARD_RECOVER_RATIO=0.45
AUTO_COST_GUARD_COOLDOWN_SEC=60
ORION_NOVA_STABLE_INTERVAL=3
NOVA_SKIP_REMOTE_AFTER_STREAK=6
NOVA_REMOTE_RETRY_INTERVAL=10
ORION_FIX_STREAK_TRIGGER=8
ORION_NO_OUTPUT_TRIGGER=4
ORION_MAX_BACKOFF_SEC=20
ECHO_TEST_INTERVAL=8
SECURITY_AUDIT_INTERVAL=12
SECURITY_FALLBACK_AUDIT_INTERVAL=20
AGENT_COORDINATION_DEDUP_WINDOW_SEC=12

# Dashboard realtime heartbeat
MONITOR_RUNTIME_HEARTBEAT_ENABLED=true
MONITOR_RUNTIME_HEARTBEAT_INTERVAL_SEC=3

# Optional dashboard token gate for production
# If set, dashboard/API/socket require token via query (?token=...) or header X-Dashboard-Token
DASHBOARD_ACCESS_TOKEN=
DASHBOARD_TOKEN_ALLOW_QUERY=true

# Fallback models
VISION_FALLBACK=gemini-3-flash
GENERAL_FALLBACK=gemini-2.5-pro
