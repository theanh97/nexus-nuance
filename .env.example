# ============================================
# NEXUS - Environment Variables
# ============================================
# Copy this file to .env and fill in your API keys
# NEVER commit .env to git!

# ============================================
# MiniMax M2.5 - PRIMARY AI MODEL
# ============================================
# Used for: OpenClaw computer control, ORION, NOVA, PIXEL, CIPHER, FLUX
MINIMAX_API_KEY=your_minimax_api_key_here
MINIMAX_MODEL=MiniMax-M2.5
MINIMAX_ANTHROPIC_BASE_URL=https://api.minimax.io/anthropic

# GLM API (z.ai) - FALLBACK MODEL
# Used for: ECHO (testing), fallback tasks
GLM_API_KEY=your_glm_api_key_here
GLM_API_BASE=https://api.z.ai/api/openai/v1
ZAI_OPENAI_BASE_URL=https://api.z.ai/api/openai/v1

# Google AI (Gemini) - Optional
GOOGLE_API_KEY=your_google_api_key_here

# ============================================
# OpenClaw - AI Computer Control
# ============================================
# OpenClaw is the AI agent that controls your computer
# Install: brew install openclaw
# Config: ~/.openclaw/openclaw.json

# OpenClaw Gateway Token (auto-read from ~/.openclaw/openclaw.json if not set)
OPENCLAW_GATEWAY_TOKEN=
OPENCLAW_BROWSER_AUTO_START=true
OPENCLAW_BROWSER_TIMEOUT_MS=30000
OPENCLAW_DASHBOARD_URL=http://127.0.0.1:5050/
OPENCLAW_AUTO_ATTACH_ENABLED=true
OPENCLAW_AUTO_ATTACH_RETRIES=2
OPENCLAW_AUTO_ATTACH_DELAY_SEC=1.2
OPENCLAW_POLICY_MOSTLY_AUTO=true
OPENCLAW_CIRCUIT_TRIGGER_COUNT=3
OPENCLAW_CIRCUIT_OPEN_SEC=60
OPENCLAW_CIRCUIT_CLASS_BLOCK_SEC=300
OPENCLAW_CIRCUIT_ESCALATE_AFTER=2
OPENCLAW_HIGH_RISK_ALLOWLIST=status,start,snapshot,open,navigate,hard_refresh,click,type,press,attach,flow
OPENCLAW_CRITICAL_KEYWORDS=shutdown,rm -rf,delete all,wipe,kill -9,format

# Distributed control-plane / guardian control
CONTROL_PLANE_DEFAULT_LEASE_TTL_SEC=35
CONTROL_PLANE_MAX_WORKERS=120
GUARDIAN_CONTROL_TOKEN=
MONITOR_AUTOPILOT_ENABLED=true
AUTONOMY_PROFILE=balanced
MONITOR_FULL_AUTO_USER_PAUSE_MAX_SEC=240
MONITOR_FULL_AUTO_MAINTENANCE_LEASE_SEC=180

# Claude Code profile (supports Anthropic-compatible and OpenAI-compatible)
# Provider options:
# - minimax / anthropic_compatible: use CLAUDE_CODE_BASE_URL directly
# - openai_compatible: auto-start local LiteLLM gateway for Claude Code
# - codaxer: same as openai_compatible but prefer CODAXER_* vars
# - auto: try Anthropic endpoint first, fallback to LiteLLM gateway
CLAUDE_CODE_PROVIDER=minimax
CLAUDE_CODE_API_KEY=your_claude_profile_key_here
CLAUDE_CODE_BASE_URL=https://api.minimax.io/anthropic
CLAUDE_CODE_MODEL=MiniMax-M2.5

# Optional model map when provider=openai_compatible
CLAUDE_CODE_MODEL_SONNET=gpt-5.1-codex
CLAUDE_CODE_MODEL_OPUS=gpt-5.1-codex-max
CLAUDE_CODE_MODEL_HAIKU=gpt-5.1-codex-mini
CLAUDE_CODE_GATEWAY_HOST=127.0.0.1
CLAUDE_CODE_GATEWAY_PORT=4000
CLAUDE_CODE_GATEWAY_TOKEN=sk-litellm-local
CLAUDE_CODE_FORCE_GATEWAY=false

# Optional fallback profile alias (works with same OpenAI-compatible gateway flow)
CODAXER_API_KEY=
CODAXER_BASE_URL=
CODAXER_MODEL_SONNET=
CODAXER_MODEL_OPUS=
CODAXER_MODEL_HAIKU=
CODAXER_MODELS=

# ============================================
# Model Configuration
# ============================================

# Routing mode:
# - adaptive: multi-model routing + fallback + budget-aware downgrade
# - single: force one model for all tasks
MODEL_ROUTING_MODE=adaptive
SINGLE_MODEL_MODE=false
DEFAULT_SINGLE_MODEL=glm-5

# Smart runtime routing retries on timeout/rate-limit/quota
ENABLE_SMART_ROUTING=true

# Daily budget controls (router tracks usage in data/state/model_usage_YYYYMMDD.json)
ROUTER_DAILY_BUDGET_USD=15
ROUTER_SOFT_BUDGET_RATIO=0.85
ROUTER_STATE_DIR=data/state
LEARNING_RUNTIME_LOCK_PATH=data/state/learning_runtime.lock
AUTODEV_RUNTIME_LOCK_PATH=data/state/autodev_runtime.lock

# Global prompt system (non-negotiable directives injected into every agent call)
ENABLE_CORE_PROMPT_SYSTEM=true
PROMPT_SYSTEM_MAX_DIRECTIVES=100
ENABLE_PROMPT_SYSTEM_TRACKLOG=true
PROMPT_SYSTEM_MAX_INJECTED_DIRECTIVES=4
PROMPT_SYSTEM_LOW_IMPORTANCE_DIRECTIVES=2
PROMPT_SYSTEM_LOW_IMPORTANCE_COMPACT=true
PROMPT_SYSTEM_INCLUDE_PROFILE_LOW_IMPORTANCE=false

# Self-learning optimization knobs
PROPOSAL_SCORE_THRESHOLD=6.2
ENABLE_AUTO_APPROVE_PROPOSALS=true
AUTO_APPROVE_PROPOSAL_SCORE=8.5
SCAN_LOG_MAX_ENTRIES=1000
PROPOSAL_HISTORY_MAX=1500
SOURCE_BACKOFF_BASE_SECONDS=600
SOURCE_BACKOFF_MAX_SECONDS=21600
MEMORY_AUTO_REPAIR_INDEX=true

# Advanced learning (spaced repetition / active recall runtime)
ENABLE_ADVANCED_LEARNING=true
ADVANCED_REVIEW_LIMIT=5
ADVANCED_INGEST_LIMIT=8
ADVANCED_LEARNING_MAX_ITEMS=800
ADVANCED_LEARNING_MAX_SESSIONS=500

# Daily R&D note logging (captures runtime issues/improvements automatically)
ENABLE_DAILY_RND_NOTES=true
RND_NOTE_MAX_MESSAGE_CHARS=800
ENABLE_ITERATION_SELF_CHECK=true
SELF_CHECK_WARN_STREAK=8
ENABLE_STAGNATION_UNBLOCK=true
UNBLOCK_MIN_PROPOSAL_SCORE=7.2
UNBLOCK_MAX_AUTO_APPROVALS_PER_ITERATION=1
ENABLE_DAILY_SELF_LEARNING=true
DAILY_SELF_LEARNING_INTERVAL_SECONDS=86400
DAILY_SELF_LEARNING_MAX_EXPERIMENTS=3
DAILY_SELF_LEARNING_MAX_IDEAS=6
DEFAULT_FOCUS_AREA=reliability
FOCUS_ROTATION_WARN_STREAK=8
SCAN_OPERATION_LOCK_PATH=data/state/knowledge_scan.lock
IMPROVEMENT_OPERATION_LOCK_PATH=data/state/improvement_apply.lock
DAILY_CYCLE_OPERATION_LOCK_PATH=data/state/daily_self_learning.lock

# Debugger storage caps
DEBUGGER_SESSION_HISTORY_MAX=300
DEBUGGER_METRICS_HISTORY_MAX=1500
DEBUGGER_RESOLVED_ISSUES_MAX=1000
DEBUGGER_OPEN_ISSUES_MAX=500

# Optional subscription profiles (used in policy chain for critical tasks)
CODEX_SUBSCRIPTION_AVAILABLE=false
CODEX_SUBSCRIPTION_MODEL=codex-5.3-x2
CODEX_SUBSCRIPTION_LOW_MODEL=codex-5.3-mini
CLAUDE_CODE_SUBSCRIPTION_AVAILABLE=false
GEMINI_SUBSCRIPTION_AVAILABLE=false
GEMINI_SUBSCRIPTION_FLASH_MODEL=gemini-3.0-flash
GEMINI_SUBSCRIPTION_PRO_MODEL=gemini-3.0-pro

# Subscription CLI integration (Codex/Claude/Gemini) for critical fallback
ENABLE_SUBSCRIPTION_FALLBACK=false
SUBSCRIPTION_FALLBACK_CRITICAL_ONLY=false
SUBSCRIPTION_FIRST_FOR_CRITICAL=false
ENABLE_SUBSCRIPTION_PRIMARY_ROUTING=false
ENABLE_AUTO_SUBSCRIPTION_COST_ROUTING=true
SUBSCRIPTION_PRIMARY_COST_ONLY=true
SUBSCRIPTION_TIMEOUT_SEC=120
SUBSCRIPTION_FAILURE_THRESHOLD=2
SUBSCRIPTION_FAILURE_COOLDOWN_SEC=180

# CLI command + args. Supports {prompt} and {model} placeholders.
# Example: CODEX_CLI_ARGS=-m {model} -p {prompt}
CODEX_CLI_CMD=codex
CODEX_CLI_ARGS=-p
CLAUDE_CLI_CMD=claude
CLAUDE_CLI_ARGS=-p
GEMINI_CLI_CMD=gemini
GEMINI_CLI_ARGS=-m {model} -p

# Primary models
ORCHESTRATOR_MODEL=glm-5
VISION_MODEL=glm-4.6v
CODE_MODEL=glm-5
SECURITY_MODEL=glm-5
TEST_MODEL=glm-4-flash
DEVOPS_MODEL=glm-5

# Orchestration cadence + cost controls
DEFAULT_COST_GUARD_MODE=balanced
AUTO_COST_GUARD_ENABLED=true
AUTO_COST_GUARD_WARN_RATIO=0.72
AUTO_COST_GUARD_HARD_RATIO=0.90
AUTO_COST_GUARD_RECOVER_RATIO=0.45
AUTO_COST_GUARD_COOLDOWN_SEC=60
ORION_NOVA_STABLE_INTERVAL=2
NOVA_SKIP_REMOTE_AFTER_STREAK=6
NOVA_REMOTE_RETRY_INTERVAL=10
ORION_FIX_STREAK_TRIGGER=8
ORION_NO_OUTPUT_TRIGGER=4
ORION_MAX_BACKOFF_SEC=20
ECHO_TEST_INTERVAL=4
SECURITY_AUDIT_INTERVAL=8
SECURITY_FALLBACK_AUDIT_INTERVAL=20

# Dashboard realtime heartbeat
MONITOR_RUNTIME_HEARTBEAT_ENABLED=true
MONITOR_RUNTIME_HEARTBEAT_INTERVAL_SEC=3

# Optional dashboard token gate for production
# If set, dashboard/API/socket require token via query (?token=...) or header X-Dashboard-Token
DASHBOARD_ACCESS_TOKEN=
DASHBOARD_TOKEN_ALLOW_QUERY=true

# Fallback models
VISION_FALLBACK=gemini-3-flash
GENERAL_FALLBACK=gemini-2.5-pro
